---
title: "Call For Papers"
bg: blue
color: white
style: center
fa-icon: line-chart
---

*We seek submissions in the following two categories:*


- Papers that describe work on the How2 data, either on the “shared challenge tasks”, e.g. multi-modal speech recognition, machine translation, or video summarization challenge, described on the How2 web site (a leader-board will be provided), or creating “un-shared”, novel tasks.
- Papers that describe other related and relevant work to further vision and language ideas by proposing new tasks, or analyzing the utility of existing tasks and data sets in interesting ways


*The organizers encourage both the publication of novel work that is relevant to the topics of discussion, and late-breaking results on the How2 tasks in a single format. The workshop will also feature a number of invited talks, and a moderated discussion around the challenges and opportunities that current tasks in vision and language present. We aim to stimulate discussion around new tasks that go beyond image captioning and visual question answering, and which could form the basis for future research in this area. We seek to create a venue to encourage collaboration between different sub-fields, and help establish new research directions that we believe will sustain multimodal machine learning research for years to come.*
