---
title: "Organizers"
bg: white 
color: black
style: center
---

### Organizers

<div class="author">
    <a href="http://www.cs.cmu.edu/~fmetze/interACT/Home.html" target="_blank">
      <div class="authorphoto"><img src="./assets/authors/florian.jpg"></div>
      <div>Florian Metze</div>
    </a>
</div>
<div class="author">
    <a href="http://staffwww.dcs.shef.ac.uk/people/L.Specia/" target="_blank">
      <div class="authorphoto"><img src="./assets/authors/lucia.jpg"></div>
      <div>Lucia Specia</div>
    </a>
</div>
<div class="author">
    <a href="https://elliottd.github.io" target="_blank">
      <div class="authorphoto"><img src="./assets/authors/des.jpg"></div>
      <div>Desmond Elliott</div>
    </a>
</div>
<div class="author">
    <a href="https://scholar.google.fr/citations?user=i4IBjw4AAAAJ&hl=fr&oi=ao" target="_blank">
      <div class="authorphoto"><img src="./assets/authors/loicResized.jpg"></div>
      <div>Lo√Øc Barrault</div>
    </a>
</div>
<div class="author">
    <a href="https://scholar.google.com/citations?user=hoE7_YcAAAAJ" target="_blank">
      <div class="authorphoto"><img src="./assets/authors/ramon.jpeg"></div>
      <div>Ramon Sanabria</div>
    </a>
</div>
<div class="author">
    <a href="https://shrutijpalaskar.github.io" target="_blank">
      <div class="authorphoto"><img src="./assets/authors/scales_image.jpg"></div>
      <div>Shruti Palaskar</div>
    </a>
</div>

For any questions, contact us at <how2challenge@gmail.com>.

* * * 

### References

<p align="left" style="font-family:font-family: TimesNewRoman,Times New Roman,Times,Baskerville,Georgia,serif;font-size:15px">
1. Palaskar et al. "End-to-End Multimodal Speech Recognition", ICASSP 2018<br>
2. Caglayan et al. "Multimodal Grounding for Sequence-to-Sequence Speech Recognition", ICASSP 2019<br>
3. Elliott et al. "Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description", WMT 2017<br>
4. Shared Task on Multimodal Machine Translation, Workshop on Machine Translation <a href="https://www.statmt.org/wmt18/multimodal-task.html">[Webpage]</a> <br>
5. Libovicky et al. "Multimodal Abstractive Summarization for Open-Domain Videos", ViGIL Workshop, NeurIPS 2018<br>
6. Holzenberger et al. "Learning from Multiview Correlations in Open-Domain Videos", ICASSP 2019<br>
7. Sanabria et al. "How2: A Large-scale Dataset for Multimodal Language Understanding", ViGIL Workshop, NeurIPS 2018<br>
</p>
